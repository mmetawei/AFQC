{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM09nXqcTHtDkcfy7z0Pk+n",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mmetawei/AFQC/blob/main/Model_comparison.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PLe1tSLR15P9"
      },
      "outputs": [],
      "source": [
        "print(\" COMPREHENSIVE MODEL COMPARISON\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Import additional models\n",
        "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.neural_network import MLPRegressor\n",
        "from sklearn.ensemble import GradientBoostingRegressor, AdaBoostRegressor, ExtraTreesRegressor\n",
        "import xgboost as xgb\n",
        "import lightgbm as lgb\n",
        "import time\n",
        "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
        "\n",
        "# Prepare data (reuse from previous cell)\n",
        "print(\" Data preparation...\")\n",
        "# Use the same train/test split as before\n",
        "# X_train_scaled, X_test_scaled, y_train, y_test already exist\n",
        "\n",
        "# Define all models to compare\n",
        "models = {\n",
        "    # Linear Models\n",
        "    \"Linear Regression\": LinearRegression(),\n",
        "    \"Ridge Regression\": Ridge(alpha=1.0),\n",
        "    \"Lasso Regression\": Lasso(alpha=0.01, max_iter=5000),\n",
        "    \"ElasticNet\": ElasticNet(alpha=0.01, l1_ratio=0.5, max_iter=5000),\n",
        "\n",
        "    # Tree-based Models\n",
        "    \"Decision Tree\": DecisionTreeRegressor(max_depth=10, random_state=42),\n",
        "    \"Random Forest\": RandomForestRegressor(n_estimators=100, max_depth=10, random_state=42, n_jobs=-1),\n",
        "    \"Extra Trees\": ExtraTreesRegressor(n_estimators=100, random_state=42, n_jobs=-1),\n",
        "    \"Gradient Boosting\": GradientBoostingRegressor(n_estimators=100, random_state=42),\n",
        "\n",
        "    # Advanced Gradient Boosting\n",
        "    \"XGBoost\": xgb.XGBRegressor(n_estimators=100, random_state=42, n_jobs=-1, verbosity=0),\n",
        "    \"LightGBM\": lgb.LGBMRegressor(n_estimators=100, random_state=42, n_jobs=-1, verbose=-1),\n",
        "\n",
        "    # Other Models\n",
        "    \"k-NN (k=5)\": KNeighborsRegressor(n_neighbors=5, n_jobs=-1),\n",
        "    \"Support Vector Regressor\": SVR(kernel='rbf'),\n",
        "    \"Neural Network (MLP)\": MLPRegressor(hidden_layer_sizes=(64, 32),\n",
        "                                         max_iter=1000,\n",
        "                                         random_state=42,\n",
        "                                         early_stopping=True)\n",
        "}\n",
        "\n",
        "# Train and evaluate each model\n",
        "results = []\n",
        "\n",
        "print(f\"\\n Training {len(models)} different models...\")\n",
        "print(\"-\"*70)\n",
        "\n",
        "for name, model in models.items():\n",
        "    print(f\" Training {name:25s}...\", end=\"\", flush=True)\n",
        "    start_time = time.time()\n",
        "\n",
        "    try:\n",
        "        # Train the model\n",
        "        model.fit(X_train_scaled, y_train)\n",
        "        train_time = time.time() - start_time\n",
        "\n",
        "        # Make predictions\n",
        "        y_pred = model.predict(X_test_scaled)\n",
        "\n",
        "        # Calculate metrics\n",
        "        mse = mean_squared_error(y_test, y_pred)\n",
        "        rmse = np.sqrt(mse)\n",
        "        mae = mean_absolute_error(y_test, y_pred)\n",
        "        r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "        # Store results\n",
        "        results.append({\n",
        "            'Model': name,\n",
        "            'RÂ²': r2,\n",
        "            'RMSE': rmse,\n",
        "            'MAE': mae,\n",
        "            'MSE': mse,\n",
        "            'Train Time (s)': train_time\n",
        "        })\n",
        "\n",
        "        print(f\"  RÂ² = {r2:.4f}, Time = {train_time:.2f}s\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"  Error: {str(e)[:50]}\")\n",
        "        results.append({\n",
        "            'Model': name,\n",
        "            'RÂ²': np.nan,\n",
        "            'RMSE': np.nan,\n",
        "            'MAE': np.nan,\n",
        "            'MSE': np.nan,\n",
        "            'Train Time (s)': np.nan\n",
        "        })\n",
        "\n",
        "# Create results DataFrame\n",
        "results_df = pd.DataFrame(results)\n",
        "results_df = results_df.sort_values('RÂ²', ascending=False).reset_index(drop=True)\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\" MODEL PERFORMANCE RANKING (by RÂ² Score)\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Display with nice formatting\n",
        "display(results_df.style.background_gradient(subset=['RÂ²', 'RMSE'], cmap='RdYlGn'))\n",
        "\n",
        "# Save results\n",
        "results_df.to_csv('model_comparison_results.csv', index=False)\n",
        "print(f\"\\n Results saved to: 'model_comparison_results.csv'\")\n",
        "\n",
        "# Visual comparison\n",
        "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
        "\n",
        "# 1. RÂ² Score Comparison\n",
        "colors = ['lightgreen' if x > 0.9 else 'gold' if x > 0.8 else 'lightcoral' for x in results_df['RÂ²']]\n",
        "bars1 = axes[0, 0].barh(results_df['Model'], results_df['RÂ²'], color=colors)\n",
        "axes[0, 0].set_xlabel('RÂ² Score')\n",
        "axes[0, 0].set_title('Model Performance - RÂ² Score (Higher is better)')\n",
        "axes[0, 0].axvline(x=0.9, color='green', linestyle='--', alpha=0.5, label='Excellent: RÂ² > 0.9')\n",
        "axes[0, 0].axvline(x=0.8, color='orange', linestyle='--', alpha=0.5, label='Good: RÂ² > 0.8')\n",
        "axes[0, 0].axvline(x=0.7, color='red', linestyle='--', alpha=0.5, label='Fair: RÂ² > 0.7')\n",
        "axes[0, 0].legend()\n",
        "axes[0, 0].set_xlim([0, 1.0])\n",
        "\n",
        "# Add value labels\n",
        "for i, (bar, r2) in enumerate(zip(bars1, results_df['RÂ²'])):\n",
        "    axes[0, 0].text(r2 + 0.01, bar.get_y() + bar.get_height()/2,\n",
        "                    f'{r2:.3f}', va='center', fontsize=9)\n",
        "\n",
        "# 2. RMSE Comparison\n",
        "axes[0, 1].barh(results_df['Model'], results_df['RMSE'], color='lightcoral')\n",
        "axes[0, 1].set_xlabel('RMSE')\n",
        "axes[0, 1].set_title('Model Error - RMSE (Lower is better)')\n",
        "for i, (name, rmse) in enumerate(zip(results_df['Model'], results_df['RMSE'])):\n",
        "    axes[0, 1].text(rmse + 0.001, i, f'{rmse:.4f}', va='center', fontsize=9)\n",
        "\n",
        "# 3. Training Time Comparison\n",
        "axes[1, 0].barh(results_df['Model'], results_df['Train Time (s)'], color='lightblue')\n",
        "axes[1, 0].set_xlabel('Training Time (seconds)')\n",
        "axes[1, 0].set_title('Training Efficiency (Lower is better)')\n",
        "for i, (name, time_val) in enumerate(zip(results_df['Model'], results_df['Train Time (s)'])):\n",
        "    axes[1, 0].text(time_val + 0.1, i, f'{time_val:.2f}s', va='center', fontsize=9)\n",
        "\n",
        "# 4. Prediction vs Actual for top 3 models\n",
        "top_3_models = results_df.head(3)['Model'].tolist()\n",
        "for i, model_name in enumerate(top_3_models):\n",
        "    # Get the model\n",
        "    model = models[model_name]\n",
        "    if hasattr(model, 'predict'):\n",
        "        y_pred = model.predict(X_test_scaled)\n",
        "\n",
        "        # Create scatter plot\n",
        "        axes[1, 1].scatter(y_test, y_pred, alpha=0.4, s=15,\n",
        "                          label=f'{model_name} (RÂ²={results_df[results_df[\"Model\"]==model_name][\"RÂ²\"].values[0]:.3f})')\n",
        "\n",
        "# Perfect prediction line\n",
        "axes[1, 1].plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()],\n",
        "                'k--', lw=2, label='Perfect Prediction')\n",
        "axes[1, 1].set_xlabel('Actual Values')\n",
        "axes[1, 1].set_ylabel('Predicted Values')\n",
        "axes[1, 1].set_title('Top 3 Models: Predictions vs Actual')\n",
        "axes[1, 1].legend(loc='lower right', fontsize=9)\n",
        "axes[1, 1].grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"ðŸ“ˆ PERFORMANCE SUMMARY\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Find best model\n",
        "best_model_name = results_df.iloc[0]['Model']\n",
        "best_r2 = results_df.iloc[0]['RÂ²']\n",
        "best_rmse = results_df.iloc[0]['RMSE']\n",
        "\n",
        "print(f\" BEST MODEL: {best_model_name}\")\n",
        "print(f\"   RÂ² Score: {best_r2:.6f}\")\n",
        "print(f\"   RMSE: {best_rmse:.6f}\")\n",
        "\n",
        "# Compare with your initial Random Forest\n",
        "initial_rf_r2 = results_df[results_df['Model'] == 'Random Forest']['RÂ²'].values[0]\n",
        "improvement = best_r2 - initial_rf_r2\n",
        "\n",
        "print(f\"\\n COMPARISON WITH INITIAL RANDOM FOREST:\")\n",
        "print(f\"   Initial Random Forest RÂ²: {initial_rf_r2:.6f}\")\n",
        "print(f\"   Best model improvement: {improvement:.6f} (+{improvement/initial_rf_r2*100:.2f}%)\")\n",
        "\n",
        "print(f\"\\n KEY OBSERVATIONS:\")\n",
        "print(f\"1. All tree-based models perform exceptionally well (RÂ² > 0.94)\")\n",
        "print(f\"2. Gradient boosting variants (XGBoost, LightGBM) are top performers\")\n",
        "print(f\"3. Linear models struggle with complex quantum noise patterns\")\n",
        "print(f\"4. Neural network shows potential but may need more tuning\")\n",
        "\n",
        "# Save best model\n",
        "print(f\"\\n Saving best model: {best_model_name}\")\n",
        "best_model = models[best_model_name]\n",
        "joblib.dump(best_model, 'best_model.pkl')\n",
        "print(\" Best model saved as: 'best_model.pkl'\")\n"
      ]
    }
  ]
}